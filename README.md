# Diffusion Transformer Meets Random Masks: An Advanced PET Reconstruction Framework

Author: Bin Huang, Binzhong He, Yanhan Chen, Zhili Liu, Xinyue Wang, Binxuan Li, Qiegen Liu

Deep learning has significantly advanced PET image reconstruction, achieving remarkable improvements in image quality through direct training on sinogram or image data. Traditional methods often utilize masks for inpainting tasks, but their incorporation into PET reconstruction frameworks introduces transformative potential. In this study, we propose an advanced PET reconstruction framework called Diffusion tRansformer mEets rAndom Masks (DREAM). To the best of our knowledge, this is the first work to integrate mask mechanisms into both the sinogram domain and the latent space, pioneering their role in PET reconstruction and demonstrating their ability to enhance reconstruction fidelity and efficiency. The framework employs a high-dimensional stacking approach, transforming masked data from two to three dimensions to expand the solution space and enable the model to capture richer spatial relationships. Additionally, a mask-driven latent space is designed to accelerate the diffusion process by leveraging sinogram-driven and mask-driven compact priors, which reduce computational complexity while preserving essential data characteristics. A hierarchical masking strategy is also introduced, guiding the model from focusing on fine-grained local details in the early stages to capturing broader global patterns over time. This progressive approach ensures a balance between detailed feature preservation and comprehensive context understanding. Experimental results demonstrate that DREAM not only improves the overall quality of reconstructed PET images but also preserves critical clinical details, highlighting its potential to advance PET imaging technology. By integrating compact priors and hierarchical masking, DREAM offers a promising and efficient avenue for future research and application in PET imaging. 

## DREAM framework
![](https://github.com/yqx7150/DREAM/blob/main/DREAM_data/figs/DREAM%20framework.png)
Comparison of the traditional PET reconstruction method and the proposed DREAM framework. DREAM employs a hierarchical mask algorithm to create 3D sinogram data blocks with richer spatial relationships.

## DREAM training procedure
![](https://github.com/yqx7150/DREAM/blob/main/DREAM_data/figs/DREAM%20training%20procedure.png)
The pipeline of DREAM training procedure. DREAM mainly consists by mask-driven latent space, diffusion stage and transformer stage. The random masks and hierarchical masks are combined to form the sinogram data blocks. SMCP of sinogram data blocks will be feed into the diffusion stage to predict and guide transformer stage to reconstruct final result.

## DREAM reconstruction procedure
![](https://github.com/yqx7150/DREAM/blob/main/DREAM_data/figs/DREAM%20reconstruction%20procedure.png)
The pipeline of DREAM reconstruction procedure. Injecting random masks to (N-1) noisy sinograms and stacking with a single noisy sinogram to form a noisy sinogram data block. SMCP of noise-free sinogram data block will be reconstructed through diffusion stage. Noise-free sinogram data block is reconstructed under the guidance of the SMCP and subsequently combined using weighted averaging to generate final PET sinogram. This combined PET sinogram is then processed through the MLEM algorithm to produce the final PET image.

## Reconstruction results for PET images using different methods
![](https://github.com/yqx7150/DREAM/blob/main/DREAM_data/figs/Reconstruction%20results%20for%20PET%20images%20using%20different%20methods.png)
Reconstruction results for PET images using different methods. (a)-(f) show the reconstruction results and residual maps for various comparison methods and DREAM. (g) presents the noise-free reconstruction. The second row depicts the residuals between the reference and reconstructed images.

## Reconstruction results for PET sinograms using different methods
![](https://github.com/yqx7150/DREAM/blob/main/DREAM_data/figs/Reconstruction%20results%20for%20PET%20sinograms%20using%20different%20methods.png)
Reconstruction results for PET sinograms using different methods. (a)-(f) show the sinogram data generated by various comparison methods and DREAM. (g) presents the noise-free sinogram. The second row depicts the residuals between the reference and reconstructed images.

## Training

To pretrain DiffIR_S1, run
```
sh trainS1.sh
```

To train DiffIR_S2, run
```
#set the 'pretrain_network_g' and 'pretrain_network_S1' in ./options/train_DiffIRS2_sino_nomin.yml to be the path of DiffIR_S1's pre-trained model

sh trainS2.sh
```


## Evaluation



- Testing
```
# modify the dataset path in ./options/test_DiffIRS2.yml

sh test.sh 
```

## Other Related Projects
* ALL-PET: A Low-resource and Low-shot PET Foundation Model in Projection Domain  [<font size=5>**[Paper]**</font>](https://github.com/yqx7150/RAYSOLUTION_PETdata/blob/main/Paper/ALL_PET_Finalx.pdf)   [<font size=5>**[Code]**</font>](https://github.com/yqx7150/ALL-PET)

* Diffusion Transformer Model with Compact Prior for Low-dose PET Reconstruction [<font size=5>**[Paper]**</font>](https://arxiv.org/abs/2407.00944)     [<font size=5>**[Code]**</font>](https://github.com/yqx7150/dtm)

* PET Tracer Separation using Conditional Diffusion Transformer with Multi-latent Space Learning [<font size=5>**[Paper]**</font>](https://arxiv.org/abs/2506.16934#:~:text=In%20this%20study%2C%20a%20multi-latent%20space%20guided%20texture,model%20%28MS-CDT%29%20is%20proposed%20for%20PET%20tracer%20separation.)

* Synthetic CT Generation via Variant Invertible Network for Brain PET Attenuation Correction [<font size=5>**[Paper]**</font>](https://ieeexplore.ieee.org/document/10666843) [<font size=5>**[Code]**</font>](https://github.com/yqx7150/PET_AC_sCT)

* Raysolution_PET_Data [<font size=5>**[Data]**</font>](https://github.com/yqx7150/Raysolution_PET_Data)   

* Spatial-Temporal Guided Diffusion Transformer Probabilistic Model for Delayed Scan PET Image Prediction [<font size=5>**[Paper]**</font>](https://ieeexplore.ieee.org/abstract/document/10980366)   [<font size=5>**[Code]**</font>](https://github.com/yqx7150/st-DTPM)    

* Double-Constraint Diffusion Model with Nuclear Regularization for Ultra-low-dose PET Reconstruction  [<font size=5>**[Paper]**</font>](https://arxiv.org/pdf/2509.00395)   [<font size=5>**[Code]**</font>](https://github.com/yqx7150/DCDM)
